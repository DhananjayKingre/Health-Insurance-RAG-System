# Health Insurance RAG Chatbot (FastAPI + Groq LLaMA3)

A production-ready **Health Insurance Question-Answering System** built using:

- **FastAPI** (Backend API)
- **Groq LLaMA3** (Ultraâ€‘fast LLM inference)
- **Vector Database (FAISS)**
- **PDF Text Extraction**
- **Advanced UI Chat Interface**
- **RAG Pipeline (Retrieve â†’ Rerank â†’ Generate)**

This project enables users to ask insurance-related questions and receive accurate answers retrieved from official policy documents.

---

## ğŸš€ What is Groq? (Short Simple Explanation)

**Groq** is a lightningâ€‘fast AI inference engine built on LPU (Language Processing Units).  
It is **100Ã— faster** than GPUs for LLMs and can generate answers in realâ€‘time with extremely low latency.  
This speed makes Groq perfect for **chatbots, RAG systems, assistants, and realâ€‘time reasoning** applications.

---

# ğŸ§  System Architecture (FastAPI RAG)

```
User Query â†’ FastAPI API â†’ Embed Query â†’ FAISS Vector Search  
â†’ Retrieve Top Relevant Chunks â†’ Groq LLaMA3 â†’ Final Answer â†’ UI
```

---

# ğŸ—„ï¸ ER Diagram (Conceptual)

```
+------------------+
|   Documents      |
+------------------+
| doc_id (PK)      |
| title            |
| content          |
| embedding[]      |
+------------------+

          1:N

+----------------------+
|   Vector_Chunks      |
+----------------------+
| chunk_id (PK)        |
| doc_id (FK)          |
| chunk_text           |
| embedding[]          |
+----------------------+
```

---

# ğŸ“‚ Project Folder Structure

```
project/
â”‚â”€â”€ data/
â”‚     â””â”€â”€ policies.pdf
â”‚â”€â”€ vectors/
â”‚     â””â”€â”€ faiss.index
â”‚     â””â”€â”€ chunks.json
â”‚â”€â”€ app/
â”‚     â”œâ”€â”€ main.py
â”‚     â”œâ”€â”€ rag_pipeline.py
â”‚     â”œâ”€â”€ embeddings.py
â”‚     â””â”€â”€ utils.py
â”‚â”€â”€ ui/
â”‚     â””â”€â”€ index.html
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md
```

---

# âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Create Virtual Environment
```
python -m venv venv
venv\Scriptsctivate
```

### 2ï¸âƒ£ Install Dependencies
```
pip install -r requirements.txt
```

### 3ï¸âƒ£ Add Groq API Key  
Create a **.env** file:

```
GROQ_API_KEY=your_api_key_here
```

---

# ğŸ§© Build Vector Database (FAISS)

Run your preprocessing script:

```
python build_vector_db.py
```

This generates:

- faiss.index  
- chunks.json  

---

# ğŸš€ Start FastAPI Server

```
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

---

# ğŸ”¥ API Endpoints

### **POST /ask**
Ask any health insurance question.

#### Example Request:
```json
{
  "question": "What illnesses are excluded from OPD coverage?"
}
```

#### Example Response:
```json
{
  "answer": "According to the policy document, OPD excludes..."
}
```

---

# ğŸ§  RAG Flow (Detailed)

1. User asks a question  
2. Query converted to embeddings  
3. FAISS returns top relevant chunks  
4. Chunks passed to Groq LLaMA3  
5. LLM generates final insurance-specific answer  
6. Response sent back to UI  

---

# ğŸ–¥ï¸ UI Chatbox Integration

Your frontend uses:

- Modern chat UI  
- Messages centered on screen  
- Auto-dismiss â€œChatbot Readyâ€ toast  
- Smooth animation  
- Supports streaming (optional)

---

# ğŸ› ï¸ Technologies Used

| Component | Technology |
|----------|------------|
| Backend | FastAPI |
| LLM | Groq LLaMA3 |
| Embeddings | HuggingFace |
| Vector DB | FAISS |
| PDF Reader | pdfminer / PyPDF |
| UI | HTML + JS |

---

# ğŸ“Œ Future Improvements

- Add Streaming Responses  
- Add User Authentication  
- Add Chat History Storage  
- Add Multiâ€‘PDF Support  
- Add Admin Dashboard  

---



---


